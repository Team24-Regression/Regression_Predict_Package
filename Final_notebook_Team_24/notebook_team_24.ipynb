{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sendy Logistics Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://cdn1.vc4a.com/media/2015/12/Sendy-delivery-900x322.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Logistics is fundamental to the success of a business while efficient and affordable logistics are a vital component of economic development. Like any logistics company, Sendy aims to improve the efficiency of businesses by providing faster delivery of their products.\n",
    "\n",
    "### About Sendy:\n",
    "Sendy is a business-to-business platform established in 2014, to enable businesses of all types and sizes to transport goods more efficiently across East Africa. It was headquartered in Kenya and has gradually expanded across the country and East African borders where  the it is enabling businesses to move large volumes of goods.\n",
    "\n",
    "### Aim and objectives:\n",
    "The aim of this notebook is to help Sendy improve their logistics and communicate an accurate arrival time to their customers. This is done through building a prediction model that estimates time of delivery of orders, from the point of driver pickup to the point of arrival at final destination. The model will enhance customer communication and improve the reliability of Sendy's services; which will ultimately improve customer experience. In addition, the solution from the model will enable Sendy to realise cost savings, and ultimately reduce the cost of doing business, through improved resource management and planning for order scheduling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn import tree\n",
    "\n",
    "#Varrible selection\n",
    "from statsmodels.graphics.correlation import plot_corr\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the csv files are converted to panda dataframe and are renamed.\n",
    "Train_df= pd.read_csv(\"Train.csv\")\n",
    "Test_df= pd.read_csv(\"Test.csv\")\n",
    "Riders_df= pd.read_csv(\"Riders.csv\")\n",
    "VariableDefinitions_df= pd.read_csv(\"VariableDefinitions.csv\")\n",
    "SampleSubmission_df= pd.read_csv(\"SampleSubmission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring data sets helps in developing deep understanding about the data, the data set is Explored with imported libraries.The Variable dataframe below displays the name of features and desciptions on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order No</th>\n",
       "      <th>Unique number identifying the order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User Id</td>\n",
       "      <td>Unique number identifying the customer on a pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vehicle Type</td>\n",
       "      <td>For this competition limited to bikes, however...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Platform Type</td>\n",
       "      <td>Platform used to place the order, there are 4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Personal or Business</td>\n",
       "      <td>Customer type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Placement - Day of Month</td>\n",
       "      <td>Placement - Day of Month i.e 1-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Placement - Weekday (Mo = 1)</td>\n",
       "      <td>Placement - Weekday (Monday = 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Placement - Time</td>\n",
       "      <td>Placement - Time - Time of day the order was p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Confirmation - Day of Month</td>\n",
       "      <td>Confirmation - Day of Month i.e 1-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Confirmation - Weekday (Mo = 1)</td>\n",
       "      <td>Confirmation - Weekday (Monday = 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Confirmation - Time</td>\n",
       "      <td>Confirmation - Time - Time of day the order wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arrival at Pickup - Day of Month</td>\n",
       "      <td>Arrival at Pickup - Day of Month i.e 1-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Arrival at Pickup - Weekday (Mo = 1)</td>\n",
       "      <td>Arrival at Pickup - Weekday (Monday = 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arrival at Pickup - Time</td>\n",
       "      <td>Time of day the the rider arrived at the locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pickup - Day of Month</td>\n",
       "      <td>Pickup - Day of Month i.e 1-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pickup - Weekday (Mo = 1)</td>\n",
       "      <td>Pickup - Weekday (Monday = 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pickup - Time</td>\n",
       "      <td>Pickup - Time - Time of day the the rider pick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Arrival at Destination - Day of Month</td>\n",
       "      <td>Arrival at Delivery - Day of Month i.e 1-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Arrival at Destination - Weekday (Mo = 1)</td>\n",
       "      <td>Arrival at Delivery - Weekday (Monday = 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Arrival at Destination - Time</td>\n",
       "      <td>Arrival at Delivery Time - Time of day the rid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Distance (KM)</td>\n",
       "      <td>The distance from Pickup to Destination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Temperature at the time of order placement in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Precipitation in millimeters</td>\n",
       "      <td>Precipitation at the time of order placement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pickup Lat</td>\n",
       "      <td>Latitude of pick up location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pickup Long</td>\n",
       "      <td>Longitude of pick up location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Destination Lat</td>\n",
       "      <td>Latitude of delivery location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Destination Long</td>\n",
       "      <td>Longitude of delivery location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Rider Id</td>\n",
       "      <td>ID of the Rider who accepted the order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Time from Pickup to Arrival</td>\n",
       "      <td>Time in seconds between 'Pickup' and 'Arrival ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Rider Metrics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rider Id</td>\n",
       "      <td>Unique number identifying the rider (same as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>No_Of_Orders</td>\n",
       "      <td>Number of Orders the rider has delivered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Age</td>\n",
       "      <td>Number of days since the rider delivered the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Average_Rating</td>\n",
       "      <td>Average rating of the rider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>No_of_Ratings</td>\n",
       "      <td>Number of ratings the rider has received. Rat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Order No  \\\n",
       "0                                     User Id   \n",
       "1                                Vehicle Type   \n",
       "2                               Platform Type   \n",
       "3                        Personal or Business   \n",
       "4                    Placement - Day of Month   \n",
       "5                Placement - Weekday (Mo = 1)   \n",
       "6                            Placement - Time   \n",
       "7                 Confirmation - Day of Month   \n",
       "8             Confirmation - Weekday (Mo = 1)   \n",
       "9                         Confirmation - Time   \n",
       "10           Arrival at Pickup - Day of Month   \n",
       "11       Arrival at Pickup - Weekday (Mo = 1)   \n",
       "12                   Arrival at Pickup - Time   \n",
       "13                      Pickup - Day of Month   \n",
       "14                  Pickup - Weekday (Mo = 1)   \n",
       "15                              Pickup - Time   \n",
       "16      Arrival at Destination - Day of Month   \n",
       "17  Arrival at Destination - Weekday (Mo = 1)   \n",
       "18              Arrival at Destination - Time   \n",
       "19                              Distance (KM)   \n",
       "20                                Temperature   \n",
       "21               Precipitation in millimeters   \n",
       "22                                 Pickup Lat   \n",
       "23                                Pickup Long   \n",
       "24                            Destination Lat   \n",
       "25                           Destination Long   \n",
       "26                                   Rider Id   \n",
       "27                Time from Pickup to Arrival   \n",
       "28                                        NaN   \n",
       "29                              Rider Metrics   \n",
       "30                                   Rider Id   \n",
       "31                               No_Of_Orders   \n",
       "32                                        Age   \n",
       "33                             Average_Rating   \n",
       "34                              No_of_Ratings   \n",
       "\n",
       "                  Unique number identifying the order  \n",
       "0   Unique number identifying the customer on a pl...  \n",
       "1   For this competition limited to bikes, however...  \n",
       "2   Platform used to place the order, there are 4 ...  \n",
       "3                                       Customer type  \n",
       "4                   Placement - Day of Month i.e 1-31  \n",
       "5                    Placement - Weekday (Monday = 1)  \n",
       "6   Placement - Time - Time of day the order was p...  \n",
       "7                Confirmation - Day of Month i.e 1-31  \n",
       "8                 Confirmation - Weekday (Monday = 1)  \n",
       "9   Confirmation - Time - Time of day the order wa...  \n",
       "10          Arrival at Pickup - Day of Month i.e 1-31  \n",
       "11           Arrival at Pickup - Weekday (Monday = 1)  \n",
       "12  Time of day the the rider arrived at the locat...  \n",
       "13                     Pickup - Day of Month i.e 1-31  \n",
       "14                      Pickup - Weekday (Monday = 1)  \n",
       "15  Pickup - Time - Time of day the the rider pick...  \n",
       "16        Arrival at Delivery - Day of Month i.e 1-31  \n",
       "17         Arrival at Delivery - Weekday (Monday = 1)  \n",
       "18  Arrival at Delivery Time - Time of day the rid...  \n",
       "19            The distance from Pickup to Destination  \n",
       "20  Temperature at the time of order placement in ...  \n",
       "21   Precipitation at the time of order placement ...  \n",
       "22                       Latitude of pick up location  \n",
       "23                      Longitude of pick up location  \n",
       "24                      Latitude of delivery location  \n",
       "25                     Longitude of delivery location  \n",
       "26             ID of the Rider who accepted the order  \n",
       "27  Time in seconds between 'Pickup' and 'Arrival ...  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30  Unique number identifying the rider (same as i...  \n",
       "31           Number of Orders the rider has delivered  \n",
       "32  Number of days since the rider delivered the f...  \n",
       "33                        Average rating of the rider  \n",
       "34   Number of ratings the rider has received. Rat...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VariableDefinitions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe above is the list of the features with a short description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 2 columns):\n",
      " #   Column                               Non-Null Count  Dtype \n",
      "---  ------                               --------------  ----- \n",
      " 0   Order No                             34 non-null     object\n",
      " 1   Unique number identifying the order  33 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 688.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "VariableDefinitions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21201 entries, 0 to 21200\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Order No                                   21201 non-null  object \n",
      " 1   User Id                                    21201 non-null  object \n",
      " 2   Vehicle Type                               21201 non-null  object \n",
      " 3   Platform Type                              21201 non-null  int64  \n",
      " 4   Personal or Business                       21201 non-null  object \n",
      " 5   Placement - Day of Month                   21201 non-null  int64  \n",
      " 6   Placement - Weekday (Mo = 1)               21201 non-null  int64  \n",
      " 7   Placement - Time                           21201 non-null  object \n",
      " 8   Confirmation - Day of Month                21201 non-null  int64  \n",
      " 9   Confirmation - Weekday (Mo = 1)            21201 non-null  int64  \n",
      " 10  Confirmation - Time                        21201 non-null  object \n",
      " 11  Arrival at Pickup - Day of Month           21201 non-null  int64  \n",
      " 12  Arrival at Pickup - Weekday (Mo = 1)       21201 non-null  int64  \n",
      " 13  Arrival at Pickup - Time                   21201 non-null  object \n",
      " 14  Pickup - Day of Month                      21201 non-null  int64  \n",
      " 15  Pickup - Weekday (Mo = 1)                  21201 non-null  int64  \n",
      " 16  Pickup - Time                              21201 non-null  object \n",
      " 17  Arrival at Destination - Day of Month      21201 non-null  int64  \n",
      " 18  Arrival at Destination - Weekday (Mo = 1)  21201 non-null  int64  \n",
      " 19  Arrival at Destination - Time              21201 non-null  object \n",
      " 20  Distance (KM)                              21201 non-null  int64  \n",
      " 21  Temperature                                16835 non-null  float64\n",
      " 22  Precipitation in millimeters               552 non-null    float64\n",
      " 23  Pickup Lat                                 21201 non-null  float64\n",
      " 24  Pickup Long                                21201 non-null  float64\n",
      " 25  Destination Lat                            21201 non-null  float64\n",
      " 26  Destination Long                           21201 non-null  float64\n",
      " 27  Rider Id                                   21201 non-null  object \n",
      " 28  Time from Pickup to Arrival                21201 non-null  int64  \n",
      "dtypes: float64(6), int64(13), object(10)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Train data set\n",
    "Train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training-set has 21201 entries and 28 features + the target variable (Time from Pickup to Arrival). 6 of the features are floats, 13 are integers and 10 are objects.Since there is a Train data set, this implies that the data has been split and any aditing that will be done on the train data set will also be applied on the Test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above,few things can be noted. some of the features need to be converted into numeric ones, so that the machine learning algorithms can process them. Furthermore. Some more features, that contain missing values (NaN = not a number) can also be spoted, that would be deal with later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are all features present in the Train data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Rider data set\n",
    "Riders_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rider_df displays the information about the motorbike riders. It consist of 5 features and 960 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Riders_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the overview of the Riders data frame. The feature (Rider Id) is common to both Riders and Train Data Frame this allows for a merge between the two data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features found within the Rider data set.\n",
    "Riders_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #a look at the submission sample data frame\n",
    "SampleSubmission_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample submission displays the format in which sumbmision would be made for this predict on Zindi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __DATA PREPROCESSING__\n",
    "\n",
    "### Data cleaning and formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Joining the riders to both Train and Test data set\n",
    "Train_df = pd.merge(Train_df, Riders_df, left_on='Rider Id', \n",
    "                    right_on='Rider Id', how='left')\n",
    "Test_df = pd.merge(Test_df, Riders_df, left_on='Rider Id',\n",
    "                    right_on='Rider Id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and Train data frames are merged with Riders data data frame on the Rider Id feature because the features in the Rider data frame may have influence on the predict variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the new merged Train data set and The same is be done for the Test data set. For the purpose of this predict, the Vehicle Type feature is dropped because only motor bikes are considered. The naming format is not consistant in the above data frame(under scores will be use instead of spaces) and Features User Id, Rider ID and Order number will be dropped but the Order No from the Test df will not be dropped since it is require dor the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', Train_df['Rider Id'].nunique(), \n",
    "      'Motorbike riders', 'and', Train_df['User Id'].nunique(), \n",
    "      'Customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Formatting the naming of the columns\n",
    "Train_df.columns = Train_df.columns.str.replace(' ', '_')\n",
    "Test_df.columns = Test_df .columns.str.replace(' ', '_')\n",
    "\n",
    "    #removing \"-\" from the feature labels.\n",
    "Train_df.columns = Train_df.columns.str.replace('_-_', '_')\n",
    "Test_df.columns = Test_df .columns.str.replace('_-_', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordin to data from Sendy; there is a missing time features 'Arrival at Destination Times' in  the Test df and it can not be culculated because the Time_from_Pickup_to_Arrival.As a result,  Arrival at Destination Times will all be dropped aswel as the Vehicle type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = Train_df.drop(['Vehicle_Type', \n",
    "                          'Arrival_at_Destination_Day_of_Month',\n",
    "                          'Arrival_at_Destination_Weekday_(Mo_=_1)',\n",
    "                          'Arrival_at_Destination_Time'], axis = 1)\n",
    "Test_df = Test_df.drop(['Vehicle_Type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Handling missing data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aval_df = Train_df.notnull().sum(axis=0).reset_index()\n",
    "aval_df.columns = ['column_name', 'missing_count']\n",
    "aval_df = aval_df.loc[aval_df['missing_count']>0]\n",
    "aval_df = aval_df.sort_values(by='missing_count')\n",
    "\n",
    "ind = np.arange(aval_df.shape[0])\n",
    "width = 0.9\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "rects = ax.barh(ind, aval_df.missing_count.values, color='magenta')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(aval_df.column_name.values, rotation='horizontal')\n",
    "ax.set_xlabel(\"Total Count of Available values\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "ax.set_title(\"Available Data In Each Column\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart above display how much data is available, the full bars means the data for that feature is comple and the last two bar bars are the only ones with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More detailed look at what data is actually missing:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Train_df missing data\n",
    "total = Train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = Train_df.isnull().sum()/Train_df.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual Display of missing Data\n",
    "ax = missing_data['Total'].plot(kind='barh', figsize=(10, 15), color='#86bf91', zorder=2, width=0.68)\n",
    "    # Set x-axis label\n",
    "ax.set_xlabel(\"Total count of missing values\", labelpad=20, weight='bold', size=12)\n",
    "\n",
    "  # Set y-axis label\n",
    "ax.set_ylabel(\"Features\", labelpad=20, weight='bold', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As obseved from both missing_data frame and the visual display above, it will be a bit tricky to deal with the 'Temparature' feature, which has 4366 missing values. However on the other hand, the 'Precipitation in mm' feature needs further investigation, but it looks like it would be better if it is dropped off from the dataset, since 97.4 % of it is missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Investigating on Precipitation in millimeter feature.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Checking if there are 0 mm records of Precipitation from both Test and Train data frame\n",
    "(Train_df['Precipitation_in_millimeters']==0).all(),(Test_df['Precipitation_in_millimeters']==0).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are no Recorded 0 values for precipitation in both of the data frames. It is not likely that pricipitation may occur in all days of the month. So it makes sense that 97% of the time in a month there is no precipitation, therefore the NaN values will be replaced with 0 values.Meaning on those days there was no precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #replacing NAN with 0 for precipitation feature\n",
    "Train_df[\"Precipitation_in_millimeters\"] = Train_df[\"Precipitation_in_millimeters\"].fillna(0)\n",
    "Test_df[\"Precipitation_in_millimeters\"] = Test_df[\"Precipitation_in_millimeters\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for relatinship between Temparature and features which may have influence of Time from Pickup to Arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    #Train_df data set \n",
    "Temp = sns.boxplot(x=\"Platform_Type\", y=\"Temperature\", hue=\"Personal_or_Business\",\n",
    "                 data=Train_df, palette=\"Greens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whisker and the box diagram propose that there is a relationship between the temparature and the platform as well as the Personal or bussiness feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #repacing the missing temparature with the mean\n",
    "Train_df = Train_df.fillna(Train_df.mean())\n",
    "Test_df = Test_df.fillna(Test_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will affect only the Temparature since it is the onlyone with the missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Data formating*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are Four features containg time data but as an object:\n",
    "\n",
    "- Placement_Time\n",
    "- Confirmation - Time\n",
    "- Arrival_at_Pickup_Time\n",
    "- Pickup_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_time(df):\n",
    "    time_matrix = ['Placement_Time','Confirmation_Time', \n",
    "                   'Arrival_at_Pickup_Time', 'Pickup_Time']\n",
    "    for i in time_matrix:\n",
    "        df[i] = pd.to_datetime(df[i]).dt.strftime('%H:%M:%S')\n",
    "        df[i] = pd.to_timedelta(df[i])\n",
    "        df[i] = df[i].dt.total_seconds()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = alter_time(Train_df)\n",
    "Test_df = alter_time(Test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new time features from the existing ones by culculating the difference from each.\n",
    "- Placement_Time\n",
    "- Confirmation - Time\n",
    "- Arrival_at_Pickup_Time\n",
    "- Pickup_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df['Placement_to_Confiration_Time'] = Train_df['Confirmation_Time'] - Train_df['Placement_Time']\n",
    "Test_df['Placement_to_Confiration_Time'] = Test_df['Confirmation_Time'] - Test_df['Placement_Time'] \n",
    "\n",
    "Train_df['Placement_to_Arrival_at_Pickup_Time'] = Train_df['Arrival_at_Pickup_Time'] - Train_df['Placement_Time']\n",
    "Test_df['Placement_to_Arrival_at_Pickup_Time'] = Test_df['Arrival_at_Pickup_Time'] - Test_df['Placement_Time'] \n",
    "\n",
    "Train_df['Placement_to_Pickup_Time'] = Train_df['Pickup_Time'] - Train_df['Placement_Time']\n",
    "Test_df['Placement_to_Pickup_Time'] = Test_df['Pickup_Time'] - Test_df['Placement_Time'] \n",
    "\n",
    "Train_df['Confirmation_to_Arrival_at_Pickup_Time'] = Train_df['Arrival_at_Pickup_Time'] - Train_df['Confirmation_Time']\n",
    "Test_df['Confirmation_to_Arrival_at_Pickup_Time'] = Test_df['Arrival_at_Pickup_Time'] - Test_df['Confirmation_Time'] \n",
    "\n",
    "Train_df['Confirmation_to_Pickup_Time'] = Train_df['Confirmation_Time'] - Train_df['Placement_Time']\n",
    "Test_df['Confirmation_to_Pickup_Time'] = Test_df['Confirmation_Time'] - Test_df['Placement_Time'] \n",
    "\n",
    "Train_df['Arrival_at_Pickup_to_Pickup_Time'] = Train_df['Confirmation_Time'] - Train_df['Placement_Time']\n",
    "Test_df['Arrival_at_Pickup_to_Pickup_Time'] = Test_df['Confirmation_Time'] - Test_df['Placement_Time'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a feature from Coordinates\n",
    "\n",
    "The haversine formula determines the great-circle distance between two points on a sphere given their longitudes and latitudes.\n",
    "Below is the fuction that will calculate the disdance between the pickup and destination location in Kilo meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_vectorize(lon1, lat1, lon2, lat2): \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2]) \n",
    "    newlon = lon2 - lon1\n",
    "    newlat = lat2 - lat1 \n",
    "    haver_formula = np.sin(newlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(newlon/2.0)**2\n",
    " \n",
    "    dist = 2 * np.arcsin(np.sqrt(haver_formula ))\n",
    "    km = 6367 * dist #6367 for distance in KM(radius of the Earth)\n",
    "    return round(km, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_1 = haversine_vectorize(Train_df['Pickup_Lat'], \n",
    "                               Train_df['Pickup_Long'], \n",
    "                               Train_df['Destination_Lat'], \n",
    "                               Train_df['Destination_Long'])\n",
    "Train_df['Actual_Distance_KM'] = distance_1\n",
    "distance_2 = haversine_vectorize(Train_df['Pickup_Lat'], \n",
    "                               Train_df['Pickup_Long'], \n",
    "                               Train_df['Destination_Lat'], \n",
    "                               Train_df['Destination_Long'])\n",
    "Test_df['Actual_Distance_KM'] = distance_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the features in the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A first look at the behaviour of delivery time (Y - Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(range(Train_df.shape[0]), np.sort(Train_df['Time_from_Pickup_to_Arrival'].values), \n",
    "            color = 'orange')\n",
    "plt.xlabel('X - Variables', fontsize=12)\n",
    "plt.ylabel('Pickup to Arrival Time', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## *Thasamy will add interpretation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to look at the Platform Type and Business type to look at what makes up most of the orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding The Distribution Of The Data\n",
    "We are going to look at the features contained in the dataframe independently.This will help with understanding the distribution of the ranges and/or types contained in each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data\n",
    "\n",
    "A look at the Platform Type and Business or Personal features to see at what makes up most of the orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train_df['Platform_Type'].value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Platform Type contribution to total orders')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "ax=sns.countplot(x='Personal_or_Business', data=Train_df)\n",
    "ax.set(xlabel='Personal or Business', ylabel='Number of orders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two figures, one can see that platfrom 3 has the highest numbers of orders and platform 4 has the least numbers. It can also be seen from the barchart that there are more orders for business than there are for personal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical data\n",
    "\n",
    "### Placement and confirmation Day of the month\n",
    "\n",
    "Placement and confirmation day of the month can be the same. If they are, it will save time that only one of the features is looked at. To check that, a new dataframe is created with rows that pass the condition that confirmation day is the same as placement day of the month. After it is created, if its length is still 21201 then this proves they are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "New_df=Train_df[Train_df['Placement_Day_of_Month']!=Train_df['Confirmation_Day_of_Month']]\n",
    "New_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "New_df=Train_df[Train_df['Placement_Weekday_(Mo_=_1)']!=Train_df['Confirmation_Weekday_(Mo_=_1)']]\n",
    "New_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are two Business orders which were not confired on the same date and day of the month and week. !!!!!what do we do with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interptre the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(Train_df['Placement_Day_of_Month'],bins=4,kde=False, color='red')\n",
    "plt.xlabel('Day of the month')\n",
    "plt.ylabel('Number of orders')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpretation chego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance\n",
    "\n",
    "The distance is looked at to see the range that contributes the most to the orders. The distance (Km) is divided into 5 ranges and is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(Train_df['Distance_(KM)'], bins=np.arange(0,60,10),kde=False, color='green')\n",
    "ax.set(xlabel='Distance(Km)', ylabel='Number of orders')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Number of orders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows that most of the orders are for a traveling distance of between 0km and 10km. Few orders are from a range 30km and 40km.\n",
    "\n",
    "### Temparature and Precipitation\n",
    "Now looking at both the temperature data and precipitation data, it can be seen that these are the only features with missing values. The graphs for boths are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2,figsize=(15,5))\n",
    "\n",
    "\n",
    "sns.distplot(Train_df['Temperature'],ax=axes[0], bins=np.arange(0,60,10),kde=False, color='orange')\n",
    "ax.set(xlabel='Temperature', ylabel='Number of orders')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Number of orders')\n",
    "\n",
    "sns.distplot(Train_df['Precipitation_in_millimeters'],ax=axes[1], bins=np.arange(0,60,10),kde=False, color='pink')\n",
    "ax.set(xlabel='Precipitation in millimeters', ylabel='Number of orders')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Number of orders')\n",
    "\n",
    "axes[0].set(xlabel=\"Temperature\", ylabel=\"Number of orders\")\n",
    "axes[1].set(xlabel=\"Precipitation in milimeters\", ylabel=\"Number of orders\")\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####interprt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(Train_df['Time_from_Pickup_to_Arrival'],bins=4,kde=False, color='red')\n",
    "plt.xlabel('Number of orders')\n",
    "plt.ylabel('Time from Pickup to Arrival')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! chego how do you interprete the above.....nb Histogram are normaly used for categorigal data with numeric...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot to display the above histplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T_PA_no_orders = sns.scatterplot(y=\"Time_from_Pickup_to_Arrival\", x =\"No_Of_Orders\",  data=Train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the scatter show that the time from pickup to arival does not depend on no of orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!! the above count plot is hard to interprete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geography And Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = sns.color_palette()\n",
    "ggplot(aes(x='Pickup_Lat', y='Pickup_Long', color= 'Time from Pickup to Arrival'), data=Train_df) + \\\n",
    "    geom_point() + \\\n",
    "    scale_color_gradient(low = 'red', high = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ggplot(aes(x='Destination_Lat', y='Destination_Long', color= 'Time_from_Pickup_to_Arrival'), data=Train_df) + \\\n",
    "    geom_point() + \\\n",
    "    scale_color_gradient(low = 'blue', high = 'yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "The distance of drop-offs are wider spread than pick up points, many destinations arrival time will be influenced by wider distances. We also notice that lengthy times for deliveries occur in both the central and outlier destinations. Traffic congestion and distance are all influential in the pick to arrival time duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the data types and the summary statistics of the variables are explored.\n",
    "Looking at the data types and number of entries of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Train_df.info() specifically outputs the number of non-null entries in each column. As such,It can be certain that the data has missing values if columns have a varying number of non-null entries.\n",
    "\n",
    "Below is the table showcasing the summary statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the means and standard deviations of different columns, The data will be standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variable Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The User ID, Order_No and Rider Id features will be dropped because they do not influence the Time_from_Pickup_to_Arrival, but the Order No feature will not be dropped from Test_df as it is required for subbmision.\n",
    "\n",
    "As it can be observed in the above table, the summary statistics being displayed is for numerical data at the moment. More importantly, all input data for regression model building purposes needs to be numerical. Therefore the text data Busines_or_Personal will be transformed  into numbers before training the machine learning model.\n",
    "\n",
    "To facilitate this transformation from textual-categorical data to numerical equivalents, pandas method called get_dummie will be used. The text data is categorical variable, and get_dummies will transform all the categorical text data into numbers by adding a column for each distinct category. The new column has a 1 for observations which were in this category, and a 0 for observations that were not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping User_Id, Order_No and Rider Id  Features\n",
    "Train_df = Train_df.drop(['Order_No', 'User_Id', 'Rider_Id'], axis = 1)\n",
    "Test_df = Test_df.drop(['User_Id', 'Rider_Id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(Train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(Train_df)\n",
    "\n",
    "# Making sure that all the column names have correct format\n",
    "df_dummies.columns = [col.replace(\" \", \"_\") for col in df_dummies.columns]\n",
    "df_dummies.columns = [col.replace(\"(Mo_=_1)\",\"Mo_1\") for col in df_dummies.columns]\n",
    "df_dummies.columns = [col.replace(\"(KM)\",\"KM\") for col in df_dummies.columns]\n",
    "# Test_df\n",
    "Test_df.columns = [col.replace(\" \", \"_\") for col in Test_df.columns]\n",
    "Test_df.columns = [col.replace(\"(Mo_=_1)\",\"Mo_1\") for col in Test_df.columns]\n",
    "Test_df.columns = [col.replace(\"(KM)\",\"KM\") for col in Test_df.columns]\n",
    "\n",
    "# Reorder columns with the dependent variable (claim_amount) the last column\n",
    "column_titles = [col for col in df_dummies.columns if col !=\n",
    "                 'Time_from_Pickup_to_Arrival'] + ['Time_from_Pickup_to_Arrival']\n",
    "df_dummies = df_dummies.reindex(columns=column_titles)\n",
    "\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations and Model Structure\n",
    "\n",
    "Using the dummy variable dataframe, a model that predictsTime from Pickup to Arrival (the dependent variable) as a function of 33 different independent variables (IVs) can be build.\n",
    "\n",
    "Before this can be done, however, its better to reorder columns so that the dependent variable is the last column of the dataframe. This will make a heatmap visualisation representing a correlation matrix of the data easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_titles = [col for col in df_dummies.columns if col!= 'Time_from_Pickup_to_Arrival'] + ['Time_from_Pickup_to_Arrival']\n",
    "df_dummies=df_dummies.reindex(columns=column_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15));\n",
    "ax = fig.add_subplot(111);\n",
    "plot_corr(df_dummies.corr(), xnames = df_dummies.corr().columns, ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all of these variables are to be used, it would be like effectively working with more than enough information. The model will also have collinearity issues:\n",
    "\n",
    "Peronal_or_Business_Personal and peronal_or_Business_Business are perfectly negative correlated. All the features having blue squeres are also perfectly negative correlated.\n",
    "This will likely be a problem when building a model.\n",
    "\n",
    "checking what an OLS model summary says."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model using statsmodels.OLS\n",
    "\n",
    "#### Generating the regression string\n",
    "Following the process initially detailed in the Multiple Linear Regression Pt 2 - Checking Model Quality train, OLS model will be build and the model summary will be printed:\n",
    "\n",
    "y ~ X\n",
    "\n",
    "which is read as follows: \"Regress y on X\". statsmodels works in a similar way, so an appropriate string need to be generated to feed to the method in case it is required to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model DataFrame with all of the columns:\n",
    "dfm = df_dummies.copy()\n",
    "\n",
    "# The dependent variable:\n",
    "y_name = 'Time_from_Pickup_to_Arrival'\n",
    "# The independent variable\n",
    "# (let's first try all of the columns in the model DataFrame)\n",
    "X_names = [col for col in dfm.columns if col != y_name]\n",
    "\n",
    "# Build the OLS formula string \" y ~ X \"\n",
    "formula_str = y_name+\" ~ \"+\" + \".join(X_names);\n",
    "print('Formula:\\n\\t {}'.format(formula_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model using the model dataframe\n",
    "model=ols(formula=formula_str, data=dfm)\n",
    "fitted = model.fit()\n",
    "\n",
    "# Output the fitted summary\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is warning about strong multicollinearity. This is likely as a result of the incorrect filtering of one hot encoded dummy variables (It was noticed earlier that Peronal_or_Business_Personal and peronal_or_Business_Business are perfectly negative correlated).\n",
    "\n",
    "In order to ensure an underlying relationship between the categories is not assumed, pd.get_dummies is called with the argument drop_first=True so that only  n-1 columns are create for each variable with n categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(Train_df, drop_first=True)\n",
    "\n",
    "# Again make sure that all the column names have underscores instead of whitespaces\n",
    "df_dummies.columns = [col.replace(\" \", \"_\") for col in df_dummies.columns]\n",
    "df_dummies.columns = [col.replace(\"(Mo_=_1)\",\"Mo_1\") for col in df_dummies.columns]\n",
    "df_dummies.columns = [col.replace(\"(KM)\",\"KM\") for col in df_dummies.columns]\n",
    "\n",
    "# Reorder columns with the dependent variable (claim_amount) the last column\n",
    "column_titles = [col for col in df_dummies.columns if col !=\n",
    "                 'Time_from_Pickup_to_Arrival'] + ['Time_from_Pickup_to_Arrival']\n",
    "df_dummies = df_dummies.reindex(columns=column_titles)\n",
    "\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are 28 columns instead of 39. This gives for 28 potential independent variables that could be used to build a relationship on Time_from_Pickup_to_Arrival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what the OLS model summary would say if now only the 30 variable columns are fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model DataFrame will be kept, but only specify the columns wanted to fit this time\n",
    "X_names = [col for col in df_dummies.columns if col != y_name]\n",
    "\n",
    "# Build the OLS formula string \" y ~ X \"\n",
    "formula_str = y_name+' ~ '+'+'.join(X_names)\n",
    "\n",
    "# Fit the model using the model dataframe\n",
    "model = ols(formula=formula_str, data=dfm)\n",
    "fitted = model.fit()\n",
    "\n",
    "# Output the fitted summary\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition number has improved, but there is still mention of strong multicollinearity in warning [2]\n",
    "\n",
    "Making further selections on the variables now using their significance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection by Correlation and Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now there are 30 predictor variables to choose from, a way of guiding is needed to choose the best ones to be predictors. One way is to look at the correlations between the Time_from_Pickup_to_Arrival and each variables in the DataFrame and select those with the strongest correlations (both positive and negative).\n",
    "\n",
    "To consider how significant those features are.\n",
    "The code below will create a new DataFrame and store the correlation coefficents and p-values in that DataFrame for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating correlations between predictor variables and the response variable\n",
    "corrs = df_dummies.corr()['Time_from_Pickup_to_Arrival'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a dictionary of correlation coefficients and p-values\n",
    "dict_cp = {}\n",
    "\n",
    "column_titles = [col for col in corrs.index if col!= 'Time_from_Pickup_to_Arrival']\n",
    "for col in column_titles:\n",
    "    p_val = round(pearsonr(df_dummies[col], df_dummies['Time_from_Pickup_to_Arrival'])[1],6)\n",
    "    dict_cp[col] = {'Correlation_Coefficient':corrs[col],\n",
    "                    'P_Value':p_val}\n",
    "\n",
    "df_cp = pd.DataFrame(dict_cp).T\n",
    "df_cp_sorted = df_cp.sort_values('P_Value')\n",
    "df_cp_sorted[df_cp_sorted['P_Value']<0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the sorted list of the p-values and correlation coefficients for each of the features, when considered on their own.\n",
    "\n",
    "If a logic test was to be used with a significance value of 5% (p-value < 0.05),it would imply that the following features are statistically significant:\n",
    "- Distance_KM\n",
    "- Average_Rating\n",
    "- the Coordinates (pick long and lat, dest long and lat)\n",
    "- No-of_Orders\n",
    "- Arrival_at_Destination_time\n",
    "- Actual_Distance\n",
    "- Placement_to_Destination_Time\n",
    "- Arrived_at_Pickup_Time\n",
    "- Placement_Day_od_Month\n",
    "- Confirmation_Day_of_Month\n",
    "- Pickup_Day_Of_Month\n",
    "- Arrival_at_Pickup_Day_of_Month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the variables that have a significant correlation with the dependent variable are kept.they will be put into an independent variable DataFrame X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependent variable remains the same:\n",
    "y_data = df_dummies[y_name]  # y_name = 'Time_from_Pickup_to_Arrival'\n",
    "\n",
    "# Model building - Independent Variable (IV) DataFrame\n",
    "X_names = list(df_cp[df_cp['P_Value'] < 0.05].index)\n",
    "X_data = df_dummies[X_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid autocorrelation,it is needed to look for predictor variable pairs which have a high correlation with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the correlation matrix\n",
    "corr = X_data.corr()\n",
    "\n",
    "# Find rows and columnd where correlation coefficients > 0.9 or <-0.9\n",
    "corr[np.abs(corr) > 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at the whole correlation matrix, it might be easier to isolate the sections of the correlation matrix to where the off-diagonal correlations are high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just like before, the correlation matrix is created\n",
    "# rows and columnd where correlation coefficients > 0.9 or <-0.9\n",
    "corr = X_data.corr()\n",
    "r, c = np.where(np.abs(corr) > 0.9)\n",
    "\n",
    "# The interest is in the off diagonal entries:\n",
    "off_diagonal = np.where(r != c)\n",
    "\n",
    "# Showing the correlation matrix rows and columns where there is  highly correlated off diagonal entries:\n",
    "corr.iloc[r[off_diagonal], c[off_diagonal]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so it looks like six of the features are very highly correlated.\n",
    "\n",
    "This is also visible looking back at the correlation coefficient heatmap and matrix from earlier, but a more focused / subset view of the matrix is useful to isolate the coefficients of interest.\n",
    "\n",
    "Distance is slightly better correlated (and lower p-value) to the dependent variable\n",
    "there fore; Arrival_at_Pickip_day_of_Month, Pickup_Day_of_Month, Confirmation_Day_of_Month and Placement_Day_of_Month are dropped form the feature dataframe. \n",
    "The resulting OLS fit summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new subset of potential independent variables\n",
    "X_remove = ['']\n",
    "X_corr_names = [col for col in X_names if col not in X_remove]\n",
    "\n",
    "# Creating new OLS formula based-upon the smaller subset\n",
    "formula_str = y_name+' ~ '+' + '.join(X_corr_names);\n",
    "print('Formula:\\n\\t{}'.format(formula_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the OLS model using the model dataframe\n",
    "model=ols(formula=formula_str, data=dfm)\n",
    "fitted = model.fit()\n",
    "\n",
    "# Display the fitted summary\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection by Variance Thresholds\n",
    "\n",
    "Variance Thresholds remove features whose values don't change much from observation to observation. The objective here is to remove all features that have a variance lower than the selected threshold.\n",
    "\n",
    "It is important to note that variance is dependent on scale, so the features will have to be normalized before implementing variance thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data into independent (X) and independent (y) variables\n",
    "X_names = list(df_dummies.columns)\n",
    "X_names.remove(y_name)\n",
    "X_data = df_dummies[X_names]\n",
    "y_data = df_dummies[y_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_data)\n",
    "X_normalize = pd.DataFrame(X_scaled, columns=X_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement Variance Threshold in Scikit Learn:\n",
    "\n",
    "Import and create an instance of the VarianceThreshold class;\n",
    "Using the .fit() method to select subset of features based on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VarianceThreshold object\n",
    "selector = VarianceThreshold(threshold=0.03)\n",
    "\n",
    "# Using the object to apply the threshold on data\n",
    "selector.fit(X_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Variance Threshold has been applied to the data.Now a closer look at the calculated variance for each predictive variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting column variances\n",
    "column_variances = selector.variances_\n",
    "\n",
    "vars_dict = {}\n",
    "vars_dict = [{\"Variable_Name\": c_name, \"Variance\": c_var}\n",
    "             for c_name, c_var in zip(X_normalize.columns, column_variances)]\n",
    "df_vars = pd.DataFrame(vars_dict)\n",
    "df_vars.sort_values(by='Variance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows the variances of the individual columns before any threshold is applied. It allows anyone to revise  initial variance threshold if there might be a need to exclude important variables.\n",
    "\n",
    "The results needs to be extracted and used to select new columns - which form a subset of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting new columns\n",
    "X_new = X_normalize[X_normalize.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "# Saving variable names for later\n",
    "X_var_names = X_new.columns\n",
    "\n",
    "# Viewing first few entries\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a threshold of 0.03, the predictor number has gone from 29 to 12 predictors.\n",
    "\n",
    "Trying few more few more thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Variance Threshold objects\n",
    "selector_1 = VarianceThreshold(threshold=0.05)\n",
    "selector_2 = VarianceThreshold(threshold=0.1)\n",
    "selector_3 = VarianceThreshold(threshold=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_1.fit(X_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_2.fit(X_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_3.fit(X_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X_normalize[X_normalize.columns[selector_1.get_support(indices=True)]]\n",
    "X_2 = X_normalize[X_normalize.columns[selector_2.get_support(indices=True)]]\n",
    "X_3 = X_normalize[X_normalize.columns[selector_3.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " graphing the number of predictors by the thresholds to investigate the relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 3), nrows=1, ncols=1)\n",
    "\n",
    "# Create list of titles and predictions to use in for loop\n",
    "subset_preds = [X_1.shape[1], X_2.shape[1], X_3.shape[1]]\n",
    "thresholds = ['0.05', '0.1', '0.15']\n",
    "\n",
    "# Plot graph\n",
    "ax.set_title('# of Predictors vs Thresholds')\n",
    "ax.set_ylabel('# of Predictors')\n",
    "ax.set_xlabel('Threshold')\n",
    "sns.barplot(x=thresholds, y=subset_preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an increase the threshold, the number of dimensions decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking what the resulting OLS fit summary for a threshold of 0.03 says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new OLS formula\n",
    "formula_str = y_name+' ~ '+' + '.join(X_new.columns)\n",
    "print('Formula:\\n\\t{}'.format(formula_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model using the model dataframe\n",
    "model = ols(formula=formula_str, data=df_dummies)\n",
    "fitted = model.fit()\n",
    "\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelling the y variable¶\n",
    "Now that the DataFrame has been shortened using various methods, Its time to see if  linear regression models can be fit and compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "Assuring that all models are trained and tested on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.columns = [col.replace(\" \", \"_\") for col in Train_df.columns]\n",
    "Train_df.columns = [col.replace(\"(Mo_=_1)\",\"Mo_1\") for col in Train_df.columns]\n",
    "Train_df.columns = [col.replace(\"(KM)\",\"KM\") for col in Train_df.columns]\n",
    "# Test_df\n",
    "Test_df.columns = [col.replace(\" \", \"_\") for col in Test_df.columns]\n",
    "Test_df.columns = [col.replace(\"(Mo_=_1)\",\"Mo_1\") for col in Test_df.columns]\n",
    "Test_df.columns = [col.replace(\"(KM)\",\"KM\") for col in Test_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = Train_df.drop(['Personal_or_Business', 'No_of_Ratings',\n",
    "                          'Age','Temperature',\n",
    "                          'Platform_Type', \"Placement_Weekday_Mo_1\", \n",
    "                          'Placement_Time','Precipitation_in_millimeters', \n",
    "                         'Confirmation_Weekday_Mo_1',\n",
    "                         'Confirmation_Time', \n",
    "                         \"Arrival_at_Pickup_Weekday_Mo_1\",\n",
    "                         'Arrival_at_Pickup_Time',\n",
    "                         'Pickup_Weekday_Mo_1', 'Pickup_Time'], axis =1)\n",
    "\n",
    "test_df = Test_df.drop(['Personal_or_Business', 'No_of_Ratings',\n",
    "                        'Age','Temperature',\n",
    "                         'Platform_Type', \"Placement_Weekday_Mo_1\", \n",
    "                          'Placement_Time','Precipitation_in_millimeters', \n",
    "                         \"Confirmation_Weekday_Mo_1\",\n",
    "                         'Confirmation_Time', \n",
    "                         \"Arrival_at_Pickup_Weekday_Mo_1\",\n",
    "                         'Arrival_at_Pickup_Time',\n",
    "                         \"Pickup_Weekday_Mo_1\", 'Pickup_Time'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Placement_Day_of_Month</th>\n",
       "      <th>Confirmation_Day_of_Month</th>\n",
       "      <th>Arrival_at_Pickup_Day_of_Month</th>\n",
       "      <th>Pickup_Day_of_Month</th>\n",
       "      <th>Distance_KM</th>\n",
       "      <th>Pickup_Lat</th>\n",
       "      <th>Pickup_Long</th>\n",
       "      <th>Destination_Lat</th>\n",
       "      <th>Destination_Long</th>\n",
       "      <th>Time_from_Pickup_to_Arrival</th>\n",
       "      <th>No_Of_Orders</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>Placement_to_Confiration_Time</th>\n",
       "      <th>Placement_to_Arrival_at_Pickup_Time</th>\n",
       "      <th>Placement_to_Pickup_Time</th>\n",
       "      <th>Confirmation_to_Arrival_at_Pickup_Time</th>\n",
       "      <th>Confirmation_to_Pickup_Time</th>\n",
       "      <th>Arrival_at_Pickup_to_Pickup_Time</th>\n",
       "      <th>Actual_Distance_KM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.317755</td>\n",
       "      <td>36.830370</td>\n",
       "      <td>-1.300406</td>\n",
       "      <td>36.829741</td>\n",
       "      <td>745</td>\n",
       "      <td>1637</td>\n",
       "      <td>13.8</td>\n",
       "      <td>264.0</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.351453</td>\n",
       "      <td>36.899315</td>\n",
       "      <td>-1.295004</td>\n",
       "      <td>36.814358</td>\n",
       "      <td>1993</td>\n",
       "      <td>396</td>\n",
       "      <td>13.6</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.308284</td>\n",
       "      <td>36.843419</td>\n",
       "      <td>-1.300921</td>\n",
       "      <td>36.828195</td>\n",
       "      <td>455</td>\n",
       "      <td>1023</td>\n",
       "      <td>12.5</td>\n",
       "      <td>199.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.281301</td>\n",
       "      <td>36.832396</td>\n",
       "      <td>-1.257147</td>\n",
       "      <td>36.795063</td>\n",
       "      <td>1341</td>\n",
       "      <td>886</td>\n",
       "      <td>14.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.266597</td>\n",
       "      <td>36.792118</td>\n",
       "      <td>-1.295041</td>\n",
       "      <td>36.809817</td>\n",
       "      <td>1214</td>\n",
       "      <td>2311</td>\n",
       "      <td>14.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21196</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.258414</td>\n",
       "      <td>36.804800</td>\n",
       "      <td>-1.275285</td>\n",
       "      <td>36.802702</td>\n",
       "      <td>9</td>\n",
       "      <td>1270</td>\n",
       "      <td>14.4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21197</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.307143</td>\n",
       "      <td>36.825009</td>\n",
       "      <td>-1.331619</td>\n",
       "      <td>36.847976</td>\n",
       "      <td>770</td>\n",
       "      <td>1023</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21198</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-1.286018</td>\n",
       "      <td>36.897534</td>\n",
       "      <td>-1.258414</td>\n",
       "      <td>36.804800</td>\n",
       "      <td>2953</td>\n",
       "      <td>314</td>\n",
       "      <td>13.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21199</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.250030</td>\n",
       "      <td>36.874167</td>\n",
       "      <td>-1.279209</td>\n",
       "      <td>36.794872</td>\n",
       "      <td>1380</td>\n",
       "      <td>2451</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21200</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.255189</td>\n",
       "      <td>36.782203</td>\n",
       "      <td>-1.320157</td>\n",
       "      <td>36.830887</td>\n",
       "      <td>2128</td>\n",
       "      <td>526</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21201 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Placement_Day_of_Month  Confirmation_Day_of_Month  \\\n",
       "0                           9                          9   \n",
       "1                          12                         12   \n",
       "2                          30                         30   \n",
       "3                          15                         15   \n",
       "4                          13                         13   \n",
       "...                       ...                        ...   \n",
       "21196                      20                         20   \n",
       "21197                      13                         13   \n",
       "21198                       7                          7   \n",
       "21199                       4                          4   \n",
       "21200                      26                         26   \n",
       "\n",
       "       Arrival_at_Pickup_Day_of_Month  Pickup_Day_of_Month  Distance_KM  \\\n",
       "0                                   9                    9            4   \n",
       "1                                  12                   12           16   \n",
       "2                                  30                   30            3   \n",
       "3                                  15                   15            9   \n",
       "4                                  13                   13            9   \n",
       "...                               ...                  ...          ...   \n",
       "21196                              20                   20            3   \n",
       "21197                              13                   13            7   \n",
       "21198                               7                    7           20   \n",
       "21199                               4                    4           13   \n",
       "21200                              26                   26           12   \n",
       "\n",
       "       Pickup_Lat  Pickup_Long  Destination_Lat  Destination_Long  \\\n",
       "0       -1.317755    36.830370        -1.300406         36.829741   \n",
       "1       -1.351453    36.899315        -1.295004         36.814358   \n",
       "2       -1.308284    36.843419        -1.300921         36.828195   \n",
       "3       -1.281301    36.832396        -1.257147         36.795063   \n",
       "4       -1.266597    36.792118        -1.295041         36.809817   \n",
       "...           ...          ...              ...               ...   \n",
       "21196   -1.258414    36.804800        -1.275285         36.802702   \n",
       "21197   -1.307143    36.825009        -1.331619         36.847976   \n",
       "21198   -1.286018    36.897534        -1.258414         36.804800   \n",
       "21199   -1.250030    36.874167        -1.279209         36.794872   \n",
       "21200   -1.255189    36.782203        -1.320157         36.830887   \n",
       "\n",
       "       Time_from_Pickup_to_Arrival  No_Of_Orders  Average_Rating  \\\n",
       "0                              745          1637            13.8   \n",
       "1                             1993           396            13.6   \n",
       "2                              455          1023            12.5   \n",
       "3                             1341           886            14.5   \n",
       "4                             1214          2311            14.1   \n",
       "...                            ...           ...             ...   \n",
       "21196                            9          1270            14.4   \n",
       "21197                          770          1023            12.5   \n",
       "21198                         2953           314            13.8   \n",
       "21199                         1380          2451            14.0   \n",
       "21200                         2128           526            13.6   \n",
       "\n",
       "       Placement_to_Confiration_Time  Placement_to_Arrival_at_Pickup_Time  \\\n",
       "0                              264.0                               1741.0   \n",
       "1                              425.0                               1446.0   \n",
       "2                              199.0                                609.0   \n",
       "3                               31.0                                742.0   \n",
       "4                               60.0                                515.0   \n",
       "...                              ...                                  ...   \n",
       "21196                           31.0                                251.0   \n",
       "21197                            7.0                                390.0   \n",
       "21198                           53.0                               1441.0   \n",
       "21199                           14.0                                440.0   \n",
       "21200                           14.0                                282.0   \n",
       "\n",
       "       Placement_to_Pickup_Time  Confirmation_to_Arrival_at_Pickup_Time  \\\n",
       "0                        3104.0                                  1477.0   \n",
       "1                        1673.0                                  1021.0   \n",
       "2                         818.0                                   410.0   \n",
       "3                        1052.0                                   711.0   \n",
       "4                         605.0                                   455.0   \n",
       "...                         ...                                     ...   \n",
       "21196                    1530.0                                   220.0   \n",
       "21197                    1193.0                                   383.0   \n",
       "21198                    2676.0                                  1388.0   \n",
       "21199                     816.0                                   426.0   \n",
       "21200                    1328.0                                   268.0   \n",
       "\n",
       "       Confirmation_to_Pickup_Time  Arrival_at_Pickup_to_Pickup_Time  \\\n",
       "0                            264.0                             264.0   \n",
       "1                            425.0                             425.0   \n",
       "2                            199.0                             199.0   \n",
       "3                             31.0                              31.0   \n",
       "4                             60.0                              60.0   \n",
       "...                            ...                               ...   \n",
       "21196                         31.0                              31.0   \n",
       "21197                          7.0                               7.0   \n",
       "21198                         53.0                              53.0   \n",
       "21199                         14.0                              14.0   \n",
       "21200                         14.0                              14.0   \n",
       "\n",
       "       Actual_Distance_KM  \n",
       "0                     2.0  \n",
       "1                    11.0  \n",
       "2                     2.0  \n",
       "3                     5.0  \n",
       "4                     3.0  \n",
       "...                   ...  \n",
       "21196                 2.0  \n",
       "21197                 3.0  \n",
       "21198                11.0  \n",
       "21199                 9.0  \n",
       "21200                 8.0  \n",
       "\n",
       "[21201 rows x 19 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                    y_data,\n",
    "                                                    test_size=0.20,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data for variance threshold model\n",
    "X_var_train = X_train[X_var_names]\n",
    "X_var_test = X_test[X_var_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data for correlation threshold model\n",
    "X_corr_train = X_train[X_corr_names]\n",
    "X_corr_test = X_test[X_corr_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting models\n",
    "instantiate and fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm_corr = LinearRegression()\n",
    "lm_var = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train);\n",
    "lm_corr.fit(X_corr_train,y_train);\n",
    "lm_var.fit(X_var_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing model accuracy\n",
    "checking how the linear models performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating figure and axes\n",
    "f, ax = plt.subplots(figsize=(15, 5), nrows=1, ncols=3, sharey=True)\n",
    "\n",
    "# Creating list of titles and predictions to use in for loop\n",
    "train_pred = [lm.predict(X_train),\n",
    "              lm_corr.predict(X_corr_train),\n",
    "              lm_var.predict(X_var_train)]\n",
    "test_pred = [lm.predict(X_test),\n",
    "             lm_corr.predict(X_corr_test),\n",
    "             lm_var.predict(X_var_test)]\n",
    "title = ['No threshold', 'Corr threshold', 'Var threshold']\n",
    "\n",
    "# Key:\n",
    "# No threshold - linear regression with all predictive variables\n",
    "# Corr threshold - linear regression with correlation thresholded predictive variables\n",
    "# Var threshold - linear regression with variance thresholded predictive variables\n",
    "\n",
    "\n",
    "# Loop through all axes to plot each model's results\n",
    "for i in range(3):\n",
    "    test_mse = round(mean_squared_error(test_pred[i], y_test), 4)\n",
    "    test_r2 = round(r2_score(test_pred[i], y_test), 4)\n",
    "    train_mse = round(mean_squared_error(train_pred[i], y_train), 4)\n",
    "    train_r2 = round(r2_score(train_pred[i], y_train), 4)\n",
    "    title_str = f\"Linear Regression({title[i]}) \\n train MSE = {train_mse} \\n \" + \\\n",
    "                f\"test MSE = {test_mse} \\n training $R^{2}$ = {train_r2} \\n \" + \\\n",
    "                f\"test $R^{2}$ = {test_r2}\"\n",
    "    ax[i].set_title(title_str)\n",
    "    ax[i].set_xlabel('Actual')\n",
    "    ax[i].set_ylabel('Predicted')\n",
    "    ax[i].plot(y_test, y_test, 'r')\n",
    "    ax[i].scatter(y_test, test_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dummy variables\n",
    "def encode_dummy(df, column_name):\n",
    "    df[column_name] =  pd.get_dummies(df[column_name],drop_first = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LASSO module\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create standardization object\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LASSO model object, setting alpha to 0.01\n",
    "lasso = Lasso(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-cf3b911276fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# split dataset into train and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m X_train, X_test, y_train, y_test = train_test_split(X_scaled,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                     \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                     \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,\n",
    "                                                    y_data,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=1,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LASSO model object, setting alpha to 0.01\n",
    "lasso = Lasso(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the LASSO model\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract intercept from model\n",
    "intercept = float(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract coefficient from model\n",
    "coeff = pd.DataFrame(lasso.coef_, Train_df.columns, columns=['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = float(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract intercept\n",
    "print(\"Intercept:\", float(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save standardized features into new variable\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train/test split module\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LASSO model object, setting alpha to 0.01\n",
    "lasso = Lasso(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = float(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.DataFrame(lasso.coef_, X.columns, columns=['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept:\", float(intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB : These functions return predicted y values for each model you call. For usage check code below the functions. A function for calculating RMSE was also added so we wont have to submit to Zindy to see our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.columns = [col.replace(\" \", \"_\") for col in Train_df.columns]\n",
    "Train_df.columns = [col.replace(\"(Mo_=_1)\",\"Mo_1\") for col in Train_df.columns]\n",
    "Train_df.columns = [col.replace(\"(KM)\",\"KM\") for col in Train_df.columns]\n",
    "# Test_df\n",
    "Test_df.columns = [col.replace(\" \", \"_\") for col in Test_df.columns]\n",
    "Test_df.columns = [col.replace(\"(Mo_=_1)\",\"Mo_1\") for col in Test_df.columns]\n",
    "Test_df.columns = [col.replace(\"(KM)\",\"KM\") for col in Test_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = Train_df.drop(['Personal_or_Business', 'No_of_Ratings',\n",
    "                          'Age','Temperature',\n",
    "                          'Platform_Type', \"Placement_Weekday_Mo_1\", \n",
    "                          'Placement_Time','Precipitation_in_millimeters', \n",
    "                         'Confirmation_Weekday_Mo_1',\n",
    "                         'Confirmation_Time', \n",
    "                         \"Arrival_at_Pickup_Weekday_Mo_1\",\n",
    "                         'Arrival_at_Pickup_Time',\n",
    "                         'Pickup_Weekday_Mo_1', 'Pickup_Time'], axis =1)\n",
    "\n",
    "test_df = Test_df.drop(['Personal_or_Business', 'No_of_Ratings',\n",
    "                        'Age','Temperature',\n",
    "                         'Platform_Type', \"Placement_Weekday_Mo_1\", \n",
    "                          'Placement_Time','Precipitation_in_millimeters', \n",
    "                         \"Confirmation_Weekday_Mo_1\",\n",
    "                         'Confirmation_Time', \n",
    "                         \"Arrival_at_Pickup_Weekday_Mo_1\",\n",
    "                         'Arrival_at_Pickup_Time',\n",
    "                         \"Pickup_Weekday_Mo_1\", 'Pickup_Time'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Placement_Day_of_Month</th>\n",
       "      <th>Confirmation_Day_of_Month</th>\n",
       "      <th>Arrival_at_Pickup_Day_of_Month</th>\n",
       "      <th>Pickup_Day_of_Month</th>\n",
       "      <th>Distance_KM</th>\n",
       "      <th>Pickup_Lat</th>\n",
       "      <th>Pickup_Long</th>\n",
       "      <th>Destination_Lat</th>\n",
       "      <th>Destination_Long</th>\n",
       "      <th>No_Of_Orders</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>Placement_to_Confiration_Time</th>\n",
       "      <th>Placement_to_Arrival_at_Pickup_Time</th>\n",
       "      <th>Placement_to_Pickup_Time</th>\n",
       "      <th>Confirmation_to_Arrival_at_Pickup_Time</th>\n",
       "      <th>Confirmation_to_Pickup_Time</th>\n",
       "      <th>Arrival_at_Pickup_to_Pickup_Time</th>\n",
       "      <th>Actual_Distance_KM</th>\n",
       "      <th>Time_from_Pickup_to_Arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.317755</td>\n",
       "      <td>36.830370</td>\n",
       "      <td>-1.300406</td>\n",
       "      <td>36.829741</td>\n",
       "      <td>1637</td>\n",
       "      <td>13.8</td>\n",
       "      <td>264.0</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.351453</td>\n",
       "      <td>36.899315</td>\n",
       "      <td>-1.295004</td>\n",
       "      <td>36.814358</td>\n",
       "      <td>396</td>\n",
       "      <td>13.6</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.308284</td>\n",
       "      <td>36.843419</td>\n",
       "      <td>-1.300921</td>\n",
       "      <td>36.828195</td>\n",
       "      <td>1023</td>\n",
       "      <td>12.5</td>\n",
       "      <td>199.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.281301</td>\n",
       "      <td>36.832396</td>\n",
       "      <td>-1.257147</td>\n",
       "      <td>36.795063</td>\n",
       "      <td>886</td>\n",
       "      <td>14.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.266597</td>\n",
       "      <td>36.792118</td>\n",
       "      <td>-1.295041</td>\n",
       "      <td>36.809817</td>\n",
       "      <td>2311</td>\n",
       "      <td>14.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Placement_Day_of_Month  Confirmation_Day_of_Month  \\\n",
       "0                       9                          9   \n",
       "1                      12                         12   \n",
       "2                      30                         30   \n",
       "3                      15                         15   \n",
       "4                      13                         13   \n",
       "\n",
       "   Arrival_at_Pickup_Day_of_Month  Pickup_Day_of_Month  Distance_KM  \\\n",
       "0                               9                    9            4   \n",
       "1                              12                   12           16   \n",
       "2                              30                   30            3   \n",
       "3                              15                   15            9   \n",
       "4                              13                   13            9   \n",
       "\n",
       "   Pickup_Lat  Pickup_Long  Destination_Lat  Destination_Long  No_Of_Orders  \\\n",
       "0   -1.317755    36.830370        -1.300406         36.829741          1637   \n",
       "1   -1.351453    36.899315        -1.295004         36.814358           396   \n",
       "2   -1.308284    36.843419        -1.300921         36.828195          1023   \n",
       "3   -1.281301    36.832396        -1.257147         36.795063           886   \n",
       "4   -1.266597    36.792118        -1.295041         36.809817          2311   \n",
       "\n",
       "   Average_Rating  Placement_to_Confiration_Time  \\\n",
       "0            13.8                          264.0   \n",
       "1            13.6                          425.0   \n",
       "2            12.5                          199.0   \n",
       "3            14.5                           31.0   \n",
       "4            14.1                           60.0   \n",
       "\n",
       "   Placement_to_Arrival_at_Pickup_Time  Placement_to_Pickup_Time  \\\n",
       "0                               1741.0                    3104.0   \n",
       "1                               1446.0                    1673.0   \n",
       "2                                609.0                     818.0   \n",
       "3                                742.0                    1052.0   \n",
       "4                                515.0                     605.0   \n",
       "\n",
       "   Confirmation_to_Arrival_at_Pickup_Time  Confirmation_to_Pickup_Time  \\\n",
       "0                                  1477.0                        264.0   \n",
       "1                                  1021.0                        425.0   \n",
       "2                                   410.0                        199.0   \n",
       "3                                   711.0                         31.0   \n",
       "4                                   455.0                         60.0   \n",
       "\n",
       "   Arrival_at_Pickup_to_Pickup_Time  Actual_Distance_KM  \\\n",
       "0                             264.0                 2.0   \n",
       "1                             425.0                11.0   \n",
       "2                             199.0                 2.0   \n",
       "3                              31.0                 5.0   \n",
       "4                              60.0                 3.0   \n",
       "\n",
       "   Time_from_Pickup_to_Arrival  \n",
       "0                          745  \n",
       "1                         1993  \n",
       "2                          455  \n",
       "3                         1341  \n",
       "4                         1214  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_titles = [col for col in train_df.columns if col !='Time_from_Pickup_to_Arrival'] + ['Time_from_Pickup_to_Arrival']\n",
    "train_df = train_df.reindex(columns=column_titles)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df.drop([\"Time_from_Pickup_to_Arrival\"], axis=1).values\n",
    "y = train_df[\"Time_from_Pickup_to_Arrival\"].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(len(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "x = sc_X.fit_transform(x)\n",
    "y = sc_y.fit_transform(y)\n",
    "x_test =test_df.drop(['Order_No'],axis = 1).copy()\n",
    "x_test = sc_X.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_v_m(x, y, x_test):\n",
    "    regressor = SVR(kernel = 'rbf')\n",
    "    regressor.fit(x, y)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELTON\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "svm_pred = sc_y.inverse_transform(s_v_m(x, y, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1088.5505074 , 1275.21469538,  931.99182226, ..., 1458.60098876,\n",
       "       1897.25595465, 1540.81668956])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = pd.DataFrame(data = svm_pred,columns = ['Time from Pickup To arrival'],\n",
    "                           index=Test_df['Order_No'])\n",
    "svm_pred.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_No</th>\n",
       "      <th>Time from Pickup To arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order_No_19248</td>\n",
       "      <td>1088.550507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order_No_12736</td>\n",
       "      <td>1275.214695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Order_No_768</td>\n",
       "      <td>931.991822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Order_No_15332</td>\n",
       "      <td>1006.968461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Order_No_21373</td>\n",
       "      <td>1016.515070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order_No  Time from Pickup To arrival\n",
       "0  Order_No_19248                  1088.550507\n",
       "1  Order_No_12736                  1275.214695\n",
       "2    Order_No_768                   931.991822\n",
       "3  Order_No_15332                  1006.968461\n",
       "4  Order_No_21373                  1016.515070"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred.to_csv(r\"C:\\Users\\ELTON\\Documents\\Final_notebook_Team_24\\svm_pred.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x, y, x_test):\n",
    "    regressor = RandomForestRegressor(n_estimators = 5, random_state = 0)\n",
    "    regressor.fit(x, y)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELTON\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "rdm_pred = sc_y.inverse_transform(random_forest(x, y, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1022. , 1472.2, 1306.2, ..., 1571.8, 1890.4, 1640.8])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_pred = pd.DataFrame(data = rdm_pred,columns = ['Time from Pickup To arrival'],\n",
    "                           index=Test_df['Order_No'])\n",
    "rdm_pred.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_No</th>\n",
       "      <th>Time from Pickup To arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order_No_19248</td>\n",
       "      <td>1022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order_No_12736</td>\n",
       "      <td>1472.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Order_No_768</td>\n",
       "      <td>1306.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Order_No_15332</td>\n",
       "      <td>1024.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Order_No_21373</td>\n",
       "      <td>1264.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order_No  Time from Pickup To arrival\n",
       "0  Order_No_19248                       1022.0\n",
       "1  Order_No_12736                       1472.2\n",
       "2    Order_No_768                       1306.2\n",
       "3  Order_No_15332                       1024.8\n",
       "4  Order_No_21373                       1264.4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_pred.to_csv(r\"C:\\Users\\ELTON\\Documents\\Final_notebook_Team_24\\rdm_pred.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X, y, X_test):\n",
    "    regressor = DecisionTreeRegressor(random_state = 0)\n",
    "    regressor.fit(X, y)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs_pred = sc_y.inverse_transform(decision_tree(x, y, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 664., 2604.,  832., ..., 2656., 1809.,  912.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs_pred = pd.DataFrame(data = dcs_pred,columns = ['Time from Pickup To arrival'],\n",
    "                           index=Test_df['Order_No'])\n",
    "dcs_pred.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_No</th>\n",
       "      <th>Time from Pickup To arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order_No_19248</td>\n",
       "      <td>664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order_No_12736</td>\n",
       "      <td>2604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Order_No_768</td>\n",
       "      <td>832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Order_No_15332</td>\n",
       "      <td>4755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Order_No_21373</td>\n",
       "      <td>832.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order_No  Time from Pickup To arrival\n",
       "0  Order_No_19248                        664.0\n",
       "1  Order_No_12736                       2604.0\n",
       "2    Order_No_768                        832.0\n",
       "3  Order_No_15332                       4755.0\n",
       "4  Order_No_21373                        832.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs_pred.to_csv(r\"C:\\Users\\ELTON\\Documents\\Final_notebook_Team_24\\dcs_pred.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_No</th>\n",
       "      <th>Time from Pickup To arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order_No_19248</td>\n",
       "      <td>664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order_No_12736</td>\n",
       "      <td>2604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Order_No_768</td>\n",
       "      <td>832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Order_No_15332</td>\n",
       "      <td>4755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Order_No_21373</td>\n",
       "      <td>832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>Order_No_3612</td>\n",
       "      <td>3208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>Order_No_7657</td>\n",
       "      <td>5264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>Order_No_1969</td>\n",
       "      <td>2656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>Order_No_10591</td>\n",
       "      <td>1809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>Order_No_1603</td>\n",
       "      <td>912.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Order_No  Time from Pickup To arrival\n",
       "0     Order_No_19248                        664.0\n",
       "1     Order_No_12736                       2604.0\n",
       "2       Order_No_768                        832.0\n",
       "3     Order_No_15332                       4755.0\n",
       "4     Order_No_21373                        832.0\n",
       "...              ...                          ...\n",
       "7063   Order_No_3612                       3208.0\n",
       "7064   Order_No_7657                       5264.0\n",
       "7065   Order_No_1969                       2656.0\n",
       "7066  Order_No_10591                       1809.0\n",
       "7067   Order_No_1603                        912.0\n",
       "\n",
       "[7068 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_regression(X, y, X_test):\n",
    "    poly_reg = PolynomialFeatures(degree = 2)\n",
    "    X_poly = poly_reg.fit_transform(X)\n",
    "    lin_reg_2 = LinearRegression()\n",
    "    lin_reg_2.fit(X_poly, y)\n",
    "    y_pred = lin_reg_2.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_linear(x, y, x_test):\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x, y)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlin_pred = multi_linear(x, y, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.76636239e+09],\n",
       "       [ 5.77280114e+09],\n",
       "       [-1.05029545e+10],\n",
       "       ...,\n",
       "       [ 7.45053752e+09],\n",
       "       [ 6.20158509e+09],\n",
       "       [ 6.95683149e+08]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlin_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_perfomance(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [21201, 7068]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-b415ff5d5d62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#svm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRMSE_perfomance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-84-94578a17c6d2>\u001b[0m in \u001b[0;36mRMSE_perfomance\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mRMSE_perfomance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m    253\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 254\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    255\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 257\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [21201, 7068]"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "print(RMSE_perfomance(y, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multi_linear(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753.5630641087931\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_perfomance(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.6"
=======
   "version": "3.7.4"
>>>>>>> 1ca0d9749ae5813c69577367f13830539aab3d96
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
